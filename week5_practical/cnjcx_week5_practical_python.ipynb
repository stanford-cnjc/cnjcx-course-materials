{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CNJCx Week 5: Practical Python\n",
    "\n",
    "Tyler Benster\n",
    "(tbenst@stanford.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "### Motivation and background\n",
    "### Hands-on coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation and background\n",
    "- Goals\n",
    "- Anti-goals\n",
    "- Extra details\n",
    "- Tidy Data\n",
    "- Today's Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Goals for today\n",
    "- \"Day in the life\" of a Pythonista\n",
    "- Whirlwhind tour of foudational packages for Data Scientists in Python\n",
    "- Exposure to opinionated best-practices for formating data and code\n",
    "- understand the \"why\" of each code block\n",
    "- know which library to use for particular analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Anti-goals for today\n",
    "- comprehend the \"how\" of each line of code\n",
    "- know which function to use for particular analyses\n",
    "- understand the math behind shown analyses\n",
    "- feeling that the class is going at a comfortable pace\n",
    "- understand how this presentation was made in a Jupyter notebook with RISE/reveal.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extra details for eager or advanced listeners\n",
    "- <details>\n",
    "    <summary><a><strong>IYI</strong></a>: If You're Interested; click me! (no seriously please do :)</summary>\n",
    "    Optional contest will be prefaced by IYI. This is not essential for understanding the presentation, and if you are at all feeling lost or confused, now is a great time to ignore what I'm saying and ask questions in the chat. IYI is inspired by David Foster Wallace's Infinite Jest.\n",
    "</details>\n",
    "- Bonus: quick peak at modern deep learning in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Easy visualization with Tidy Data\n",
    "![tidy data](https://r4ds.had.co.nz/images/tidy-1.png)\n",
    "\n",
    "See Hadley Wickham's [publication](https://www.jstatsoft.org/article/view/v059i10) for more details and motivation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hands-on coding\n",
    "- Data visualization: how to make some basic plots (matplotlib, Altair)\n",
    "- (5 minute break)\n",
    "- Advanced data analysis: interrogate the data and visualize(scipy.stats, sklearn)\n",
    "- how to read in common data formats (images, MAT v6/v7, HDF5, csv)\n",
    "- data munging: what data structures and patterns to use for optimal efficiency (numpy, pytorch tensor, pandas, tidy data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First-up: matplotlib\n",
    "matplotlib is the most popular plotting library in Python, and is a swiss army knife that can do virtually anything. It's also the most manual difficult to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some example data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in iris.items():\n",
    "    if not key in ['data', 'target']:\n",
    "        print(f\"=========\\n{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's create a basic scatter plot using the procedural (scripting) interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(iris.data[:,0], iris.data[:,2])\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we create subplots with coloring & legend using the alternate Object-oriented interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "axes[0].scatter(iris.data[:,0], iris.data[:,1], c=iris.target)\n",
    "axes[0].set_xlabel(iris.feature_names[0])\n",
    "axes[0].set_ylabel(iris.feature_names[1])\n",
    "scatter1 = axes[1].scatter(iris.data[:,2], iris.data[:,3], c=iris.target)\n",
    "axes[1].set_xlabel(iris.feature_names[2])\n",
    "axes[1].set_ylabel(iris.feature_names[3])\n",
    "axes[1].legend(scatter1.legend_elements()[0],\n",
    "               iris.target_names, title=\"Species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Uh oh, that looks terrible. Here's a quick fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Better, but legend location still problematic.\n",
    "\n",
    "**IYI**: This can be fixed using low-level arguments like `bbox`, see [here](https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Surely there's a better way??\n",
    "Introducing the \"Grammar of Graphics\"! Other python GoG packages include Seaborn and Holoviews. We use Altair, as it is implemented on the cross-language Vega-lite, so what you learn today can also be done in Julia or even used for interactive web-charts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![grammar of graphics](https://miro.medium.com/max/2000/1*mcLnnVdHNg-ikDbHJfHDNA.png)\n",
    "\n",
    "**IYI** conceptual guide [here](https://towardsdatascience.com/a-comprehensive-guide-to-the-grammar-of-graphics-for-effective-visualization-of-multi-dimensional-1f92b4ed4149)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducing pandas: convient tables in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's install a python package with example datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install vega_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next we load an example DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "import altair as alt, pandas as pd\n",
    "\n",
    "cars_df = data.cars()\n",
    "print(f\"object type: {type(cars_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "DataFrames have some convenient methods to help us inspect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some of these methods can be chained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.Name.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here we select a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df[\"Name\"][402]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look at the type of each Series (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's see the various Origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.Origin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can easily do `where` queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df[cars_df.Origin=='USA'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Or chain multiple requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "idxs = np.all([cars_df.Origin=='USA',\n",
    "              cars_df.Horsepower>200,\n",
    "              cars_df.Year<=datetime(1972,1,1)],\n",
    "             axis=0)\n",
    "cars_df[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plotting Tidy Data with Altair\n",
    "Since our data is Tidy, we can use the Grammar of Graphics to make plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "line = alt.Chart(cars_df).mark_line().encode(\n",
    "    x='Year',\n",
    "    y='mean(Miles_per_Gallon)'\n",
    ")\n",
    "# https://altair-viz.github.io/user_guide/generated/core/altair.ErrorBandDef.html#altair.ErrorBandDef\n",
    "band = alt.Chart(cars_df).mark_errorband(extent='ci').encode(\n",
    "    x='Year',\n",
    "    y=alt.Y('Miles_per_Gallon', title='Miles/Gallon'),\n",
    ")\n",
    "\n",
    "band + line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The power of this approach becomes especially apparent with complex plots that would require a lot of work for each axis with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "line = alt.Chart(cars_df).mark_line().encode(\n",
    "    x='Year',\n",
    "    y=alt.Y('mean(Miles_per_Gallon)', title=\"average MPG\"),\n",
    "    color='Cylinders:O' # we specify that the data is Ordinal, meaning ordered\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ").facet(\n",
    "    facet='Origin:N', # data is Nominal, meaning categorical\n",
    "    columns=3\n",
    ")\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Excercise 1: make a scatter plot of Horsepower vs Acceleration, colored by Origin\n",
    "Instead of `mark_line`, use `mark_point`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# your code here...feel free to refer to cells above!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's quickly revist the Iris dataset and show off our new skills!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "iris_df = data.iris()\n",
    "\n",
    "alt.Chart(iris_df).mark_circle().encode(\n",
    "    alt.X('sepalLength', scale=alt.Scale(zero=False)),\n",
    "    alt.Y('sepalWidth', scale=alt.Scale(zero=False, padding=1)),\n",
    "    color='species',\n",
    "    size='petalWidth'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, **IYI**, here's a more advanced figure: an interactive scatter & Violin plot using `selection`, `transform_filter`, and `transform_density`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "brush = alt.selection(type='interval', resolve='global')\n",
    "scatter = alt.Chart(cars_df).mark_point().encode(\n",
    "    x=alt.X('Horsepower'),\n",
    "    y=alt.Y('Acceleration'),\n",
    "    color=alt.condition(brush, 'Origin', alt.ColorValue('gray'))\n",
    ")\n",
    "\n",
    "violin = alt.Chart(cars_df).transform_filter(\n",
    "    brush\n",
    ").transform_density(\n",
    "    'Miles_per_Gallon',\n",
    "    as_=['Miles_per_Gallon', 'density'],\n",
    "    extent=[5, 50],\n",
    "    groupby=['Origin']\n",
    ").mark_area(orient='horizontal').encode(\n",
    "    y='Miles_per_Gallon:Q',\n",
    "    color='Origin:N',\n",
    "    x=alt.X(\n",
    "        'density:Q',\n",
    "        stack='center',\n",
    "        impute=None,\n",
    "        title=None,\n",
    "        axis=alt.Axis(labels=False, values=[0],grid=False, ticks=True),\n",
    "    ),\n",
    "    column=alt.Column(\n",
    "        'Origin:N',\n",
    "        header=alt.Header(\n",
    "            titleOrient='bottom',\n",
    "            labelOrient='bottom',\n",
    "            labelPadding=0,\n",
    "        ),\n",
    "    )\n",
    ").properties(\n",
    "    width=100\n",
    ")\n",
    "\n",
    "\n",
    "plot = (scatter | violin).add_selection(\n",
    "# scatter.add_selection(\n",
    "    brush\n",
    ").configure_facet(\n",
    "     spacing=0\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# try drawing a box on the scatter plot!B\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For more, checkout this example gallery of beautiful plots with shockingly few lines of code: https://altair-viz.github.io/gallery/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (5 minute break)\n",
    "\n",
    "**IYI** A poem while we wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP below here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in trial-summed response of retinal ganglion cells\n",
    "# to a 0.5s flash of light\n",
    "rgcs_df = pd.read_csv(\"rgc_light_response.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each column with number is a 1ms time bin that sums\n",
    "# the number of Action potentials from `ntrials`.\n",
    "# i, j index the 2D electrode array.\n",
    "# unit_num identifies puported individual neurons recorded from each electrode.\n",
    "rgcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgcs_tidy = pd.melt(rgcs_df, id_vars=['retina', 'id', 'ntrials'],\n",
    "        var_name=\"time_bin\",\n",
    "        value_name=\"spike_count\",\n",
    "        value_vars=list(map(str, np.arange(3500))))\n",
    "# 100ms time bins\n",
    "time_bin = 1000\n",
    "rgcs_tidy[\"time\"] = (pd.to_numeric(rgcs_tidy.time_bin) + 1) / time_bin\n",
    "rgcs_tidy[\"firing_rate\"] = rgcs_tidy.spike_count / rgcs_tidy.ntrials * time_bin\n",
    "rgcs_tidy.drop(columns=[\"spike_count\", \"ntrials\", \"time_bin\"], inplace=True)\n",
    "rgcs_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgcs_tidy.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# limitation with Altair...very slow with lots of rows!\n",
    "# This plot may eventually work but will take a loooong time\n",
    "# so don't try this right now :)\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "line = alt.Chart(rgcs_tidy).mark_line(\n",
    "    stroke=\"black\"\n",
    ").encode(\n",
    "    x=\"time:Q\",\n",
    "    y=\"mean(firing_rate)\",\n",
    "#     detail=\"firing_rate\"\n",
    ")\n",
    "\n",
    "darkness = pd.DataFrame({\"start\": [0.0,1.5], \"end\":[1.0, 3.5]})\n",
    "\n",
    "# See Vega-lite docuentation on rect mark\n",
    "# https://vega.github.io/vega/docs/marks/rect/\n",
    "rect = alt.Chart(darkness).mark_rect(\n",
    "    fillOpacity=0.1,\n",
    "    fill='black'\n",
    ").encode(\n",
    "    x='start',\n",
    "    x2='end',\n",
    ")\n",
    "\n",
    "\n",
    "line+rect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a nSamples x nFeatures matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgc_mat = np.array(rgcs_tidy.pivot(index='id', columns='time', values='firing_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgc_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "from typing import Tuple\n",
    "time = np.arange(rgc_mat.shape[1])/1000 # convert to seconds\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, rgc_mat.mean(0))\n",
    "ylim = ax.get_ylim()\n",
    "# Create a Rectangle patch\n",
    "\n",
    "def make_rect(start:float, duration:float, ylim:Tuple[float, float]):\n",
    "    return patches.Rectangle((start, ylim[0]), duration, ylim[1],\n",
    "                             facecolor='black', alpha=0.1)\n",
    "\n",
    "# we make small helper function to follow DRY: Don't repeat yourself\n",
    "rect1 = make_rect(0,1, ylim)\n",
    "rect2 = make_rect(1.5,2, ylim)\n",
    "\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect1)\n",
    "ax.add_patch(rect2)\n",
    "ax.set_xlim(0,3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.convolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "# estimate firing rate using gaussian smoothing\n",
    "sigma = 6\n",
    "bandwidth = 0.05 # sec\n",
    "bin_width = 0.001\n",
    "transformed_sigma = bandwidth/bin_width\n",
    "window = signal.gaussian(2*sigma*transformed_sigma, std=transformed_sigma)[None]\n",
    "\n",
    "# instantaneous firing rate (acausal)\n",
    "ifr = signal.convolve(rgc_mat, window,mode=\"same\")/(transformed_sigma*np.sqrt(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rgc_trace(ax, trace, time=time,\n",
    "                   light_on=1, light_off=1.5):\n",
    "    ax.plot(time,trace)\n",
    "    ylim = ax.get_ylim()\n",
    "    rect1 = make_rect(0,1, ylim)\n",
    "    rect2 = make_rect(1.5,2, ylim)\n",
    "    ax.add_patch(rect1)\n",
    "    ax.add_patch(rect2)\n",
    "    ax.set_xlim(0,3.5)\n",
    "    ax.set_xlabel(\"time (s)\")\n",
    "    ax.set_ylabel(\"firing rate (Hz)\")\n",
    "\n",
    "fig, axes = plt.subplots(5,2, figsize=(8,8))\n",
    "plot_rgc_trace(axes[0,0], rgc_mat[200])\n",
    "axes[0,0].set_title(\"Trial-average firing rate\")\n",
    "axes[0,1].set_title(\"Instantaneous firing rate\")\n",
    "plot_rgc_trace(axes[0,1], ifr[200])\n",
    "\n",
    "for i,c in zip(range(1,5),[500,1500,2000,2500]):\n",
    "    plot_rgc_trace(axes[i,0], rgc_mat[c])\n",
    "    plot_rgc_trace(axes[i,1], ifr[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold.t_sne import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "projected_data = pca.fit_transform(ifr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(projected_data[:,0], projected_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "# This is slow, so we only fit on every 10th cell for demonstration purposes\n",
    "tsne_data = tsne.fit_transform(ifr[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_data[:,0], tsne_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "optics = OPTICS(xi=0.05,min_samples=25)\n",
    "optics.fit(projected_data)\n",
    "\n",
    "plt.hist(optics.labels_, bins=np.arange(optics.labels_.max()+1))\n",
    "plt.title(\"Count by cluster label\")\n",
    "print(f\"fraction unclustered: {sum(optics.labels_==-1)/len(projected_data):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = optics.labels_.max()+1 # 0-index\n",
    "unit_interval_class = optics.labels_ / num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [cm.tab20(f) if f>=0 else cm.colors.to_rgba(\"gray\")\n",
    "          for f in unit_interval_class[::10]]\n",
    "plt.scatter(tsne_data[:,0], tsne_data[:,1],\n",
    "            color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgcs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgcs_with_cluster = rgcs_df.copy()\n",
    "rgcs_with_cluster[\"cluster\"] = optics.labels_\n",
    "# filter to include only clustered cells\n",
    "rgcs_with_cluster = rgcs_with_cluster[rgcs_with_cluster.cluster!=-1]\n",
    "tidy_data = pd.melt(rgcs_with_cluster, id_vars=['retina', 'id', 'ntrials', \"cluster\"],\n",
    "        var_name=\"time_bin\",\n",
    "        value_name=\"spike_count\",\n",
    "        value_vars=list(map(str, np.arange(35))))\n",
    "# 100ms time bins\n",
    "tidy_data[\"time\"] = pd.to_numeric(tidy_data.time_bin) / 10\n",
    "tidy_data[\"firing_rate\"] = tidy_data.spike_count / tidy_data.ntrials * 10\n",
    "tidy_data.drop(columns=[\"spike_count\", \"ntrials\", \"time_bin\"], inplace=True)\n",
    "tidy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(tidy_data).mark_line().encode(\n",
    "    x = \"time\",\n",
    "    y = \"mean(firing_rate)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hd\n",
    "from hdbscan import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install vega_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan\n",
    "optics.labels_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = \"retina,id,i,j,unit_num,ntrials\".split(\",\") + list(map(str,np.arange(3500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"/home/tyler/Dropbox/Science/manuscripts/2019_acuity_paper/acuity_paper/code/integrity_units_1ms.csv\",\n",
    "                 index_col=False,\n",
    "                 names=cols)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv[np.logical_not(csv.retina.str.contains(\"BENAQ\"))].drop_duplicates(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.to_csv(\"rgc_light_response.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = alt.Chart(cars_df).mark_point().encode(\n",
    "    x=alt.X('Horsepower', bin=True),\n",
    "    y=alt.Y('Acceleration', bin=True),\n",
    "    size=\"count()\"\n",
    "    \n",
    ")\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
