{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CNJCx Week 5: Practical Python\n",
    "\n",
    "Tyler Benster\n",
    "(tbenst@stanford.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "### Motivation and background\n",
    "### Hands-on coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation and background\n",
    "- Goals\n",
    "- Anti-goals\n",
    "- Extra details\n",
    "- Tidy Data\n",
    "- Today's Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Goals for today\n",
    "- \"Day in the life\" of a Pythonista\n",
    "- Whirlwhind tour of foudational packages for Data Scientists in Python\n",
    "- Exposure to opinionated best-practices for formating data and code\n",
    "- understand the \"why\" of each code block\n",
    "- know which library to use for particular analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Anti-goals for today\n",
    "- comprehend the \"how\" of each line of code\n",
    "- know which function to use for particular analyses\n",
    "- understand the math behind shown analyses\n",
    "- feeling that the class is going at a comfortable pace\n",
    "- understand how this presentation was made in a Jupyter notebook with RISE/reveal.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Extra details for eager or advanced listeners\n",
    "- <details>\n",
    "    <summary><a><strong>IYI</strong></a>: If You're Interested; click me! (no seriously please do :)</summary>\n",
    "    Optional content will be prefaced by IYI. This is not essential for understanding the presentation, and if you are at all feeling lost or confused, now is a great time to ignore what I'm saying and ask questions in the chat. IYI is inspired by David Foster Wallace's Infinite Jest.\n",
    "</details>\n",
    "- Bonus: quick peak at modern deep learning in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Easy visualization with Tidy Data\n",
    "![tidy data](https://r4ds.had.co.nz/images/tidy-1.png)\n",
    "\n",
    "See Hadley Wickham's [publication](https://www.jstatsoft.org/article/view/v059i10) for more details and motivation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hands-on coding\n",
    "- Data visualization: how to make some basic plots (matplotlib, Altair)\n",
    "- (5 minute break)\n",
    "- Advanced data analysis: interrogate the data and visualize(scipy.stats, sklearn)\n",
    "- how to read in common data formats (csv)\n",
    "- data munging: what data structures and patterns to use for optimal efficiency (numpy, pytorch tensor, pandas, tidy data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Get this notebook running\n",
    "1. open a terminal\n",
    "2. navigate to folder where you want the code, e.g. `mkdir -p ~/code && cd code`\n",
    "3. `git clone https://github.com/tbenst/cnjcx-course-materials.git`\n",
    "\n",
    "4. `cd cnjcx-course-materials`\n",
    "5. `git checkout week5`\n",
    "6. Activate your environment\n",
    "7. `pip install -r requirements.txt`\n",
    "8. `jupyter notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First-up: matplotlib\n",
    "matplotlib is the most popular plotting library in Python, and is a swiss army knife that can do virtually anything. It's also the most involved to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some example data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# load data\n",
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for key, value in iris.items():\n",
    "    if not key in ['data', 'target']:\n",
    "        print(f\"=========\\n{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's create a basic scatter plot using the procedural (scripting) interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(iris.data[:,0], iris.data[:,2])\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we create subplots with coloring & legend using the alternate Object-oriented interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=2)\n",
    "axes[0].scatter(iris.data[:,2], iris.data[:,3], c=iris.target)\n",
    "axes[0].set_xlabel(iris.feature_names[2])\n",
    "axes[0].set_ylabel(iris.feature_names[3])\n",
    "scatter1 = axes[1].scatter(iris.data[:,0], iris.data[:,1], c=iris.target)\n",
    "axes[1].set_xlabel(iris.feature_names[0])\n",
    "axes[1].set_ylabel(iris.feature_names[1])\n",
    "axes[1].legend(scatter1.legend_elements()[0],\n",
    "               iris.target_names, title=\"Species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Uh oh, that looks terrible. Here's a quick fix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Better, but legend location still problematic.\n",
    "\n",
    "**IYI**: This can be fixed using low-level arguments like `bbox`, see [here](https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Surely there's a better way??\n",
    "Introducing the \"Grammar of Graphics\"! Other python GoG packages include Seaborn and Holoviews. We use **Altair**, as it is implemented on the cross-language Vega-lite, so what you learn today can also be done in Julia or even used for interactive web-charts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![grammar of graphics](https://miro.medium.com/max/2000/1*mcLnnVdHNg-ikDbHJfHDNA.png)\n",
    "\n",
    "**IYI** conceptual guide [here](https://towardsdatascience.com/a-comprehensive-guide-to-the-grammar-of-graphics-for-effective-visualization-of-multi-dimensional-1f92b4ed4149)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducing pandas: convient tables in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let's install a python package with example datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install vega_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next we load an example DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "import altair as alt, pandas as pd\n",
    "\n",
    "cars_df = data.cars()\n",
    "print(f\"object type: {type(cars_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "DataFrames have some convenient methods to help us inspect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some of these methods can be chained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.Name.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here we select a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df[\"Name\"][402]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take a look at the type of each Series (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's see the various Origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df.Origin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can easily do `where` queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cars_df[cars_df.Origin=='USA'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Or chain multiple requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "idxs = np.all([cars_df.Origin=='USA',\n",
    "              cars_df.Horsepower>200,\n",
    "              cars_df.Year<=datetime(1972,1,1)],\n",
    "             axis=0)\n",
    "cars_df[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plotting Tidy Data with Altair\n",
    "Since our data is Tidy, we can use the Grammar of Graphics to make plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "line = alt.Chart(cars_df).mark_line().encode(\n",
    "    x='Year',\n",
    "    y='mean(Miles_per_Gallon)'\n",
    ")\n",
    "# https://altair-viz.github.io/user_guide/generated/core/altair.ErrorBandDef.html#altair.ErrorBandDef\n",
    "band = alt.Chart(cars_df).mark_errorband(extent='ci').encode(\n",
    "    x='Year',\n",
    "    y=alt.Y('Miles_per_Gallon', title='Miles/Gallon'),\n",
    ")\n",
    "\n",
    "band + line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The power of this approach becomes especially apparent with complex plots that would require a lot of work for each axis with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "line = alt.Chart(cars_df).mark_line().encode(\n",
    "    x='Year',\n",
    "    y=alt.Y('mean(Miles_per_Gallon)', title=\"average MPG\"),\n",
    "    color='Cylinders:O' # we specify that the data is Ordinal, meaning ordered\n",
    ").properties(\n",
    "    width=180,\n",
    "    height=180\n",
    ").facet(\n",
    "    facet='Origin:N', # data is Nominal, meaning categorical\n",
    "    columns=3\n",
    ")\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Excercise 1: make a scatter plot of Horsepower vs Acceleration, colored by Origin\n",
    "Instead of `mark_line`, use `mark_point`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# your code here...feel free to refer to cells above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's quickly revist the Iris dataset and show off our new skills!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "iris_df = data.iris()\n",
    "\n",
    "alt.Chart(iris_df).mark_circle().encode(\n",
    "    alt.X('sepalLength', scale=alt.Scale(zero=False)),\n",
    "    alt.Y('sepalWidth', scale=alt.Scale(zero=False, padding=1)),\n",
    "    color='species',\n",
    "    size='petalWidth'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, **IYI**, here's a more advanced figure: an interactive scatter & Violin plot using `selection`, `transform_filter`, and `transform_density`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "brush = alt.selection(type='interval', resolve='global')\n",
    "scatter = alt.Chart(cars_df).mark_point().encode(\n",
    "    x=alt.X('Horsepower'),\n",
    "    y=alt.Y('Acceleration'),\n",
    "    color=alt.condition(brush, 'Origin', alt.ColorValue('gray'))\n",
    ")\n",
    "\n",
    "violin = alt.Chart(cars_df).transform_filter(\n",
    "    brush\n",
    ").transform_density(\n",
    "    'Miles_per_Gallon',\n",
    "    as_=['Miles_per_Gallon', 'density'],\n",
    "    extent=[5, 50],\n",
    "    groupby=['Origin']\n",
    ").mark_area(orient='horizontal').encode(\n",
    "    y='Miles_per_Gallon:Q',\n",
    "    color='Origin:N',\n",
    "    x=alt.X(\n",
    "        'density:Q',\n",
    "        stack='center',\n",
    "        impute=None,\n",
    "        title=None,\n",
    "        axis=alt.Axis(labels=False, values=[0],grid=False, ticks=True),\n",
    "    ),\n",
    "    column=alt.Column(\n",
    "        'Origin:N',\n",
    "        header=alt.Header(\n",
    "            titleOrient='bottom',\n",
    "            labelOrient='bottom',\n",
    "            labelPadding=0,\n",
    "        ),\n",
    "    )\n",
    ").properties(\n",
    "    width=100\n",
    ")\n",
    "\n",
    "\n",
    "plot = (scatter | violin).add_selection(\n",
    "# scatter.add_selection(\n",
    "    brush\n",
    ").configure_facet(\n",
    "     spacing=0\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# try drawing a box on the scatter plot!B\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For more, checkout this example gallery of beautiful plots with shockingly few lines of code: https://altair-viz.github.io/gallery/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (5 minute break)\n",
    "\n",
    "**IYI** A poem while we wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data munging\n",
    "\n",
    "Suppose you get data from a collaborator. How might you read a csv and convert to Tidy Data?\n",
    "\n",
    "We'll look at some data collected by Darwin Babino @ University of Washington. Each row contains the trial-summed response to a 0.5s flash of light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Read in csv file to DataFrame\n",
    "rgcs_df = pd.read_csv(\"rgc_light_response.csv\")\n",
    "\n",
    "# Each column with number is a 1ms time bin that sums\n",
    "# the number of Action potentials from `ntrials`.\n",
    "# i, j index the 2D electrode array.\n",
    "# unit_num identifies puported individual neurons recorded from each electrode.\n",
    "rgcs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Note: if you're coming from Matlab, you might be tempted to write a for loop\n",
    "# sometimes this can't be avoided, but in general writing for-loops is discouraged\n",
    "# in Python. They are slow in interpreted languages and usually there's a better way\n",
    "\n",
    "rgcs_tidy = pd.melt(rgcs_df, id_vars=['retina', 'id', 'ntrials'],\n",
    "        var_name=\"time_bin\",\n",
    "        value_name=\"spike_count\",\n",
    "        value_vars=list(map(str, np.arange(3500))))\n",
    "rgcs_tidy.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Normalize spike count by number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 1ms time bins\n",
    "time_bin = 1000\n",
    "rgcs_tidy[\"time\"] = (pd.to_numeric(rgcs_tidy.time_bin) + 1) / time_bin\n",
    "rgcs_tidy[\"firing_rate\"] = rgcs_tidy.spike_count / rgcs_tidy.ntrials * time_bin\n",
    "rgcs_tidy.drop(columns=[\"spike_count\", \"ntrials\", \"time_bin\"], inplace=True)\n",
    "rgcs_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# limitation with Altair...very slow with lots of rows!\n",
    "# This plot will work if you uncomment the next line\n",
    "# but may be slow, so don't try this right now :)\n",
    "\n",
    "# alt.data_transformers.disable_max_rows()\n",
    "\n",
    "line = alt.Chart(rgcs_tidy).mark_line(\n",
    "    stroke=\"black\"\n",
    ").encode(\n",
    "    x=\"time:Q\",\n",
    "    y=\"mean(firing_rate)\",\n",
    "#     detail=\"firing_rate\"\n",
    ")\n",
    "\n",
    "darkness = pd.DataFrame({\"start\": [0.0,1.5], \"end\":[1.0, 3.5]})\n",
    "\n",
    "# See Vega-lite docuentation on rect mark\n",
    "# https://vega.github.io/vega/docs/marks/rect/\n",
    "rect = alt.Chart(darkness).mark_rect(\n",
    "    fillOpacity=0.1,\n",
    "    fill='black'\n",
    ").encode(\n",
    "    x='start',\n",
    "    x2='end',\n",
    ")\n",
    "\n",
    "\n",
    "line+rect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead, let's prepare to plot with matplotlib. First, we create a nSamples x nFeatures matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# effectively, this undoes our melt operation\n",
    "rgcs_tidy.pivot(index='id', columns='time', values='firing_rate').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# convert to ndarray\n",
    "rgc_mat = np.array(rgcs_tidy.pivot(index='id', columns='time', values='firing_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import patches\n",
    "from typing import Tuple\n",
    "time = np.arange(rgc_mat.shape[1])/1000 # convert to seconds\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, rgc_mat.mean(0))\n",
    "ylim = ax.get_ylim()\n",
    "# Create a Rectangle patch\n",
    "\n",
    "def make_rect(start:float, duration:float, ylim:Tuple[float, float]):\n",
    "    return patches.Rectangle((start, ylim[0]), duration, ylim[1],\n",
    "                             facecolor='black', alpha=0.1)\n",
    "\n",
    "# we make small helper function to follow DRY: Don't repeat yourself\n",
    "rect1 = make_rect(0,1, ylim)\n",
    "rect2 = make_rect(1.5,2, ylim)\n",
    "\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect1)\n",
    "ax.add_patch(rect2)\n",
    "ax.set_xlim(0,3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Calculating instantaneous firing rate\n",
    "$\\omega(\\tau) = \\frac{1}{\\sqrt{2\\pi}\\sigma_\\omega}\\exp\\left({-\\frac{\\tau^2}{2\\sigma_\\omega^2}}\\right)$\n",
    "\n",
    "(to type this in markdown):\n",
    "```\n",
    "$\\omega(\\tau) = \\frac{1}{\\sqrt{2\\pi}\\sigma_\\omega}\\exp\\left({-\\frac{\\tau^2}{2\\sigma_\\omega^2}}\\right)$\n",
    "```\n",
    "\n",
    "**IYI**: see 1.11 from [Dayan and Abbott](http://www.gatsby.ucl.ac.uk/~lmate/biblio/dayanabbott.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "# estimate firing rate using gaussian smoothing\n",
    "sigma = 6\n",
    "bandwidth = 0.05 # sec\n",
    "bin_width = 0.001\n",
    "transformed_sigma = bandwidth/bin_width\n",
    "window = signal.gaussian(2*sigma*transformed_sigma,\n",
    "                         std=transformed_sigma)[None]\n",
    "\n",
    "# instantaneous firing rate (acausal)\n",
    "ifr = signal.convolve(rgc_mat, window,mode=\"same\") \\\n",
    "             / (transformed_sigma*np.sqrt(2*np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_rgc_trace(ax, trace, time=time,\n",
    "                   light_on=1, light_off=1.5):\n",
    "    ax.plot(time,trace)\n",
    "    ylim = ax.get_ylim()\n",
    "    rect1 = make_rect(0,1, ylim)\n",
    "    rect2 = make_rect(1.5,2, ylim)\n",
    "    ax.add_patch(rect1)\n",
    "    ax.add_patch(rect2)\n",
    "    ax.set_xlim(0,3.5)\n",
    "    ax.set_xlabel(\"time (s)\")\n",
    "    ax.set_ylabel(\"firing rate (Hz)\")\n",
    "\n",
    "fig, axes = plt.subplots(5,2, figsize=(8,8))\n",
    "plot_rgc_trace(axes[0,0], rgc_mat[13])\n",
    "axes[0,0].set_title(\"Trial-average firing rate\")\n",
    "axes[0,1].set_title(\"Instantaneous firing rate\")\n",
    "plot_rgc_trace(axes[0,1], ifr[13])\n",
    "\n",
    "for i,c in zip(range(1,6),[33, 23, 19, 21]):\n",
    "    plot_rgc_trace(axes[i,0], rgc_mat[c])\n",
    "    plot_rgc_trace(axes[i,1], ifr[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical analysis\n",
    "Now that we have experience with some data munging and visualization, let's try our hand at a quick statistical analysis using **scipy**!\n",
    "\n",
    "Question: In Iris dataset, does sepal length vary in a statistically significant way across the three species?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# let's take a quick look at the data for intuition\n",
    "alt.Chart(iris_df).mark_bar().encode(\n",
    "    x=alt.X(\"sepalWidth\", bin=alt.Bin(step=0.25)),\n",
    "    y=\"count(sepalWidth)\",\n",
    "    color=\"species\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We run an ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "species = iris_df.species.unique()\n",
    "data = [iris_df.sepalWidth[iris_df.species == s] for s in species]\n",
    "F, p = stats.f_oneway(*data)\n",
    "# We reject the null\n",
    "F, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## sklearn: a unified interface to machine learning\n",
    "As long as your data can be organized into a nSamples x nFeatures matrix and fits in RAM, you can use sklearn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try our hand at dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# turn species into vector of integers\n",
    "species_vector = iris_df.species.astype('category').cat.codes\n",
    "\n",
    "# drop species & create data matrix\n",
    "data = np.array(iris_df.iloc[:,:-1])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "projected_data = pca.fit_transform(data)\n",
    "\n",
    "plt.scatter(projected_data[:,0], projected_data[:,1],\n",
    "           c = species_vector)\n",
    "\n",
    "# IYI: try adding a legend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster \n",
    "kmeans = cluster.KMeans(n_clusters=3)\n",
    "kmeans.fit(data)\n",
    "\n",
    "plt.hist(kmeans.labels_, bins=np.arange(kmeans.labels_.max()+2))\n",
    "plt.title(\"Count by cluster label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.scatter(projected_data[:,0], projected_data[:,1],\n",
    "           c = species_vector)\n",
    "plt.title(\"True labels\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(projected_data[:,0], projected_data[:,1],\n",
    "           c = kmeans.labels_)\n",
    "plt.title(\"Clustered labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "tsne_data = tsne.fit_transform(data)\n",
    "\n",
    "plt.scatter(tsne_data[:,0], tsne_data[:,1],\n",
    "           c = species_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus: Variational auto-encoder in PyTorch\n",
    "\n",
    "This download may take a while, so feel free to just watch :)\n",
    "\n",
    "![mnist](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n",
    "!mkdir -p mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch import nn, optim, utils\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn import functional as F\n",
    "import torchvision.utils\n",
    "from functools import partial\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "torch.manual_seed(20200909) # reproducible analysis\n",
    "\n",
    "batch_size = 64\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "mnist_train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./mnist', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./mnist', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "# shape is batch_size x 1 x 28 x 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Now witness the firepower of this fully armed and operational Notebook!\n",
    "\n",
    "**IYI**: see a full presentation [here](https://github.com/tbenst/cnjc-vae/blob/master/main.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# subclass PyTorch Module for reverse-mode autodifferentiation \n",
    "# for easy backpropogation of loss gradient\n",
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, nfeatures,nlatent=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.nfeatures = nfeatures\n",
    "        self.nhidden = int(nfeatures/5)\n",
    "        \n",
    "        # nn.Linear is a \"dense\" layer of form y = Ax + b\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.hidden_encoder = nn.Linear(nfeatures, self.nhidden)\n",
    "        # mean encoding layer \n",
    "        self.mean_encoder = nn.Linear(self.nhidden, nlatent)\n",
    "        # log variance encoding layer \n",
    "        self.logvar_encoder = nn.Linear(self.nhidden, nlatent)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.hidden_decoder = nn.Linear(nlatent, int(nfeatures/5))\n",
    "        self.reconstruction_decoder = nn.Linear(self.nhidden, nfeatures)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # we use a ReLu (rectified linear unit) activation function\n",
    "        h1 = F.relu(self.hidden_encoder(x))\n",
    "        return self.mean_encoder(h1), self.logvar_encoder(h1)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        \"\"\"Reparameterize out stochastic node so the gradient can propogate \n",
    "           deterministically.\"\"\"\n",
    "\n",
    "        if self.training:\n",
    "            standard_deviation = torch.exp(0.5*logvar)\n",
    "            # sample from unit gaussian with same shape as standard_deviation\n",
    "            epsilon = torch.randn_like(standard_deviation)\n",
    "            return epsilon * standard_deviation + mean\n",
    "        else:\n",
    "            return mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.hidden_decoder(z))\n",
    "        # use sigmoid to bound output to (0,1)\n",
    "        return F.sigmoid(self.reconstruction_decoder(h3))\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"A special method in PyTorch modules that is called by __call__\"\n",
    "        \n",
    "        # flatten batch x height x width into batch x nFeatures, then encode\n",
    "        mean, logvar = self.encode(x.view(-1, self.nfeatures))\n",
    "        # sample an embedding, z\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        # return the (sampled) reconstruction, mean, and log variance\n",
    "        return self.decode(z), mean, logvar\n",
    "    \n",
    "def loss_function(recon_x, x, mu, logvar, nfeatures):\n",
    "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, nfeatures), size_average=False)\n",
    "\n",
    "    # we want KLD = - 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # where sigma is standard deviation and mu is mean\n",
    "    # (interested? check out Appendix B of https://arxiv.org/abs/1312.6114)\n",
    "    # In pytorch, x^2 is written as x.pow(2), e^x is written as x.exp(),\n",
    "    # and sum_{i=1}^n (x_i + y_i) for x,y of length n\n",
    "    # can be written as torch.sum(x+y)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "def train(epoch, model, optimizer, train_loader, log_interval=10):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data[0].to(device)  # we ignore any labels & transfer to GPU\n",
    "        nfeatures = data[0].numel()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar, nfeatures)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch, model, test_loader,folder=\"results\"):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data[0].to(device)\n",
    "            nfeatures = data[0].numel()\n",
    "            n = min(data.size(0), 15)\n",
    "            if len(data.shape)==3:\n",
    "                  # zebrafish\n",
    "                _, H, W = data.shape\n",
    "                dat = data[:n,None]\n",
    "            elif len(data.shape)==4:\n",
    "                  # MNIST\n",
    "                _, _, H, W = data.shape\n",
    "                dat = data[:n]\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar, nfeatures).item()\n",
    "            if i == 0:              \n",
    "                comparison = torch.cat([dat,\n",
    "                                   recon_batch.view(-1, 1, H, W)[:n]])\n",
    "                torchvision.utils.save_image(comparison.cpu(),\n",
    "                         folder+'/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# run cell to reset model\n",
    "nfeatures = 28**2\n",
    "# we use a latent space of dimension 2 as to get an easy-to-visualize manifold\n",
    "# (see mnist/sample_*.png while running next cell)\n",
    "nlatent = 2\n",
    "mnist_model = VAE(nfeatures,nlatent=nlatent).to(device)\n",
    "mnist_optimizer = optim.Adam(mnist_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this will take two minutes to run.\n",
    "# As it does, check out the mnist folder!\n",
    "# each epoch, reconstruction examples are saved (original on top) \n",
    "# select files on right, then refresh, and double click image\n",
    "# click bottom right corner of image to resize\n",
    "\n",
    "nepochs = 5\n",
    "H, W = (28,28)\n",
    "\n",
    "# make grid of z1 x z2 where z1,z2 \\elem (-3.5,-2.5, ..., 3.5)\n",
    "nrow = 25\n",
    "latents = torch.zeros(nrow,nrow,nlatent)\n",
    "z1_tick = np.linspace(-3.5,3.5,nrow)\n",
    "z2_tick = np.linspace(-3.5,3.5,nrow)\n",
    "for i, z1 in enumerate(z1_tick):\n",
    "    for j, z2 in enumerate(z2_tick):\n",
    "        latents[i,j,[0,1]] = torch.FloatTensor([z1,z2])\n",
    "latents = latents.to(device)\n",
    "\n",
    "for epoch in range(1, nepochs + 1):\n",
    "    train(epoch, mnist_model, mnist_optimizer, mnist_train_loader)\n",
    "    test(epoch, mnist_model, mnist_test_loader,folder='mnist')\n",
    "    with torch.no_grad():\n",
    "        latent_space = mnist_model.decode(latents.view(-1,nlatent)).cpu()\n",
    "        torchvision.utils.save_image(latent_space.view(-1, 1, H, W),\n",
    "                   'mnist/sample_' + str(epoch) + '.png',nrow=nrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thanks for tuning in!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
